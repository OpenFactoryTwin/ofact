{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Read Basic State Model\n",
    "\n",
    "By reading the Excel file and generating the python state model, the state model can be stored as '.pkl' file.\n",
    "The '.pkl' file is faster in reading than the Excel file, but should be updated if the Excel file is changed.\n",
    "The '.pkl' file is generated automatically after the Excel file is deserialized."
   ],
   "id": "48cb68af7a6e8e0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from ofact.planning_services.model_generation.persistence import deserialize_state_model\n",
    "from ofact.twin.repository_services.deserialization.order_types import OrderType\n",
    "\n",
    "from projects.bicycle_world.settings import PROJECT_PATH\n",
    "print(PROJECT_PATH)"
   ],
   "id": "96cba60493ad3e61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path_to_model = \"scenarios/current/models/twin/\"\n",
    "state_model_file_name = \"base_wo_material_supply.xlsx\"\n",
    "\n",
    "state_model_file_path = Path(str(PROJECT_PATH), path_to_model + state_model_file_name)\n",
    "state_model_generation_settings = {\"order_generation_from_excel\": False,\n",
    "                                   \"customer_generation_from_excel\": True,\n",
    "                                   \"customer_amount\": 5, \n",
    "                                   \"order_amount\": 20,\n",
    "                                   \"order_type\": OrderType.PRODUCT_CONFIGURATOR}\n",
    "state_model = deserialize_state_model(state_model_file_path, persistence_format=\"xlsx\",\n",
    "                                      state_model_generation_settings=state_model_generation_settings)"
   ],
   "id": "58365bb884aa06c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get an insight in the available orders:",
   "id": "7ec9289f52b9bfb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "available_orders = state_model.get_orders()\n",
    "first_n_orders = 1\n",
    "for order in available_orders[:first_n_orders]:\n",
    "    print(f\"The order with the identifier '{order.identifier}' \"\n",
    "          f\"ordered on '{order.order_date}' is planned to deliver on '{order.delivery_date_planned}'.\")\n",
    "\n",
    "    print(f\"\\n The requested features of the order are ({len(order.features_requested)}): \")\n",
    "    features_requested = pd.DataFrame([[feature.feature_cluster.name, feature.name] \n",
    "                                       for feature in order.features_requested],\n",
    "                                      columns=[\"Feature Cluster\", \"Feature Name\"])\n",
    "    print(features_requested)\n",
    "\n",
    "    print(f\"\\n The completed features of the order are ({len(order.features_completed)}): \")\n",
    "    features_completed = pd.DataFrame([[feature.feature_cluster.name, feature.name]\n",
    "                                       for feature in order.features_completed],\n",
    "                                      columns=[\"Feature Cluster\", \"Feature Name\"])\n",
    "    print(features_completed)\n",
    "    print(\"\\n\\n\\n\")"
   ],
   "id": "47aeac7856446ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get an insight in the available resources:",
   "id": "3b083b32abe7414f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_resources = state_model.get_all_resources()\n",
    "\n",
    "print(\"How many resources are available in the state model?\")\n",
    "print(len(all_resources))\n",
    "\n",
    "warehouses = state_model.get_warehouses()\n",
    "work_stations = state_model.get_work_stations()\n",
    "\n",
    "storages = state_model.get_storages()\n",
    "\n",
    "active_moving_resources = state_model.get_active_moving_resources()\n",
    "passive_moving_resources = state_model.get_passive_moving_resources()\n"
   ],
   "id": "1740f0288d95b458",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get an insight in the available parts:",
   "id": "8ca0a577922b4ac4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parts = state_model.get_parts()\n",
    "\n",
    "print(\"How many parts are available in the state model?\")\n",
    "print(len(parts))\n",
    "\n",
    "print(\"How many different parts are available in the state model?\")\n",
    "print(len(set(part.entity_type for part in parts)))"
   ],
   "id": "ad34707efc44f501",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get an insight in the available processes:",
   "id": "1b9f1e1009e7edfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_processes = state_model.get_all_processes()\n",
    "\n",
    "print(\"How many processes are available in the state model?\")\n",
    "print(len(all_processes))\n",
    "\n",
    "n = 1\n",
    "value_added_processes = state_model.get_value_added_processes()\n",
    "print(\"Which value added processes are in the state model?\")\n",
    "\n",
    "value_added_processes_df = pd.DataFrame([value_added_process.name\n",
    "                                         for value_added_process in value_added_processes[:min(n, len(value_added_processes))]],\n",
    "                                        columns=[\"Value Added Process Name\"])\n",
    "\n",
    "processes = state_model.get_processes()\n",
    "print(\"Which normal processes are in the state model?\")\n",
    "\n",
    "processes_df = pd.DataFrame([process.name\n",
    "                             for process in processes[:min(n, len(processes))]],\n",
    "                             columns=[\"Process Name\"])\n",
    "process_df = pd.concat([value_added_processes_df, processes_df],\n",
    "                       axis=1)\n",
    "print(process_df)"
   ],
   "id": "728d51bada8e68ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Data from Shop Floor\n",
    "\n",
    "Take a look in the available data files from our \"bicycle world\" scenario.\n",
    "- Event Log/ Execution Log Data\n",
    "- Order Data"
   ],
   "id": "f885905319464f35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "d9137c97bb010418",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# read the source files\n",
    "execution_log_df = pd.read_excel(\"../data/input/executions.xlsx\")\n",
    "\n",
    "print(execution_log_df.columns.values)\n",
    "print(execution_log_df.head())"
   ],
   "id": "6d93e72e5971222f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the execution log file, we have a list of all executed processes.\n",
    "Each row has the following data:\n",
    "- process information (link to the executed process identification and/ or name)\n",
    "- time information (start and end time of the process)\n",
    "- order information (link to the associated order)\n",
    "- resource information (link to the associated resource(s))\n",
    "- (input) part information (link to the associated part(s))\n",
    "- transition information (origin and destination resource required to specify the transport or transfer)\n",
    "- quality information (specify the resulting quality of the transformed parts)\n",
    "\n",
    "These data entries are required to update the state model of the digital twin.\n",
    "However, this is just one example of how the data entry might look like.\n",
    "Diverging data structures are also possible, such as standard event logs.\n",
    "In event logs, a process can have multiple entries, e.g., an entry is created for each event.\n",
    "Data gaps (missing data) can also be handled as part of the data integration.\n"
   ],
   "id": "4fb5029e29b9d46f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# read the source files\n",
    "order_pool_df = pd.read_excel(\"../data/input/orders.xlsx\")\n",
    "\n",
    "print(order_pool_df.columns.values)\n",
    "print(order_pool_df.head())"
   ],
   "id": "68fd776b249137de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the order pool log file, we have a list of all orders.\n",
    "They could be already finished, currently in progress or planned.\n",
    "Each row has the following data:\n",
    "- order information (link to the order identification and/ or name)\n",
    "- customer information (link to the associated customer)\n",
    "- price information (How many does the order cost?)\n",
    "- product information (link to the associated product (part) and/or the product class (type of the product))\n",
    "- time information (timestamps of the order lifecycle \n",
    "    - ('Order Date', 'Release Date', 'Delivery Date Requested', 'Delivery Date Planned', 'Delivery Date Actual'))\n",
    "- urgency information (Is the order urgent?)\n",
    "- feature information (describes the product specifications chosen by the customer)\n",
    "    - Features are mapped to processes (in the static state model). \n",
    "      The order is finished through executing a set of processes that are required to add the chosen features to the product\n",
    "\n",
    "These data entries are required to update the state model of the digital twin.\n",
    "However, this is just one example of how the data entry might look like.\n",
    "Diverging data structures are also possible.\n",
    "For example, if the order in a use case is based on BOMs or processes rather than on features, features could be added artificially.\n",
    "As mentioned previously for the event logs, data gaps (missing data) can be handled as part of the data integration.\n"
   ],
   "id": "506de6197fd20f7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Update the digital twin state model based on the data source model.",
   "id": "d916a354583376d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from ofact.twin.state_model.model import _transform_order_pool_list_to_np_array\n",
    "from ofact.settings import ROOT_PATH\n",
    "\n",
    "from projects.bicycle_world.scenarios.current.data_integration.update_digital_twin import get_digital_twin_updated"
   ],
   "id": "c39a8e0f1ba200ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "state_model.orders = _transform_order_pool_list_to_np_array([])  # shouldn't be mandatory\n",
    "\n",
    "start_datetime = datetime(2024, 10, 22, 8)\n",
    "end_datetime = None  # datetime(2024, 10, 29)\n",
    "\n",
    "data_source_model_path = Path(str(PROJECT_PATH),\n",
    "                              \"scenarios/current/models/data_source/data_source_model.xlsx\")\n",
    "\n",
    "updated_state_model = get_digital_twin_updated(ROOT_PATH, PROJECT_PATH,\n",
    "                                               state_model, start_datetime, end_datetime, data_source_model_path)"
   ],
   "id": "a455215c93f855d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Persist the updated state model",
   "id": "92825e618e2f8a08"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In addition to the static data modeled in the Excel sheets, we have added dynamic data to the state model.\n",
    "For the serialization, we need to add the \"dynamics\" flag."
   ],
   "id": "d0e16745703181de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ofact.twin.repository_services.persistence import serialize_state_model\n",
    "\n",
    "target_file_path = \"../../tutorial/updated_state_model.pkl\"\n",
    "serialize_state_model(state_model=updated_state_model, target_file_path=target_file_path,\n",
    "                      dynamics=True)"
   ],
   "id": "f9ee542f158b164a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "125059d625f0d5bf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
